{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dcolinmorgan/grph/blob/main/quick_bench.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "219c6516-e381-4d41-aebb-a17704888e5a",
      "metadata": {
        "id": "219c6516-e381-4d41-aebb-a17704888e5a"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --extra-index-url=https://pypi.nvidia.com cuml-cu11==22.10.0 cudf-cu11==22.10.0 cugraph-cu11==22.10.0 pylibraft_cu11==22.10.0 raft_dask_cu11==22.10.0 dask_cudf_cu11==22.10.0 pylibcugraph_cu11==22.10.0 pylibraft_cu11==22.10.0\n",
        "!pip install -U git+https://github.com/graphistry/pygraphistry.git@cudf #-cat-final\n",
        "!pip install -U git+https://github.com/graphistry/cu-cat.git  # # @ #cu_cat_regpt"
      ],
      "metadata": {
        "id": "pZ2B17Vp2EY1"
      },
      "id": "pZ2B17Vp2EY1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cuml,cudf\n",
        "cuml.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dg58Olv22IS1",
        "outputId": "1fd61dce-46bd-4ad3-bac4-3e7790c2bffa"
      },
      "id": "dg58Olv22IS1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'22.10.00a+119.gb30ef85c1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"0.01.0\" > VERSION.txt\n",
        "# !cp VERSION.txt /root/.local/lib/python3.9/site-packages/cu_cat/\n",
        "!cp VERSION.txt /usr/local/lib/python3.9/dist-packages/cu_cat/"
      ],
      "metadata": {
        "id": "iGnFPi8x2IVW"
      },
      "id": "iGnFPi8x2IVW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from importlib import reload\n",
        "# reload(cu_cat)\n",
        "import cu_cat\n",
        "print(cu_cat.__file__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQJKUVqZ2IXr",
        "outputId": "d8fc4917-a4a4-4ce7-a09d-67f40308e8eb"
      },
      "id": "oQJKUVqZ2IXr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/cu_cat/__init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9da43cdd-e7c2-45e2-83cb-e7b6a3efe896",
      "metadata": {
        "id": "9da43cdd-e7c2-45e2-83cb-e7b6a3efe896"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from collections import Counter\n",
        "import cProfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pstats import Stats\n",
        "import cudf\n",
        "from time import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "pd.set_option('display.max_colwidth', 200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af47c1f6-003b-4585-9722-c13d9a93eb4b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "af47c1f6-003b-4585-9722-c13d9a93eb4b",
        "outputId": "4fdcda0e-437e-43c3-a66b-155b321dc7fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.28.7+422.g19e9f6c'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import graphistry\n",
        "\n",
        "graphistry.register(api=3,protocol=\"https\", server=\"hub.graphistry.com\", username='dcolinmorgan', password='***') ## key id, secret key\n",
        "\n",
        "# graphistry.register(api=3,protocol=\"https\", server=\"hub.graphistry.com\", username='dcolinmorgan', password='***') ## key id, secret key\n",
        "graphistry.__version__\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dirty_cat"
      ],
      "metadata": {
        "id": "JAGuCnaz2UmD"
      },
      "id": "JAGuCnaz2UmD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5w567tn2Uok",
        "outputId": "f54e4ee9-fb55-43ff-c48e-d9903e3f6ec0"
      },
      "id": "D5w567tn2Uok",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Apr 20 06:30:24 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    27W /  70W |    103MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# run independently"
      ],
      "metadata": {
        "id": "nLOETLTC-vhr"
      },
      "id": "nLOETLTC-vhr"
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "qvx9mTLLaWi6"
      },
      "id": "qvx9mTLLaWi6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=1"
      ],
      "metadata": {
        "id": "xrzf3ha3Vp2H"
      },
      "id": "xrzf3ha3Vp2H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c00b3f92-9e41-4e0d-82e5-70cc4fce5e91",
      "metadata": {
        "id": "c00b3f92-9e41-4e0d-82e5-70cc4fce5e91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "90874338-c58e-4aa2-ae3d-6f6ce61a22b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Featurizing nodes with feature_engine=dirty_cat\n",
            "Using GPU: dirty_cat\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-c0ab088d82ad>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# for jj,j in enumerate(['cu_cat','dirty_cat']):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeaturize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_engine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dirty_cat'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/graphistry/feature_utils.py\u001b[0m in \u001b[0;36mfeaturize\u001b[0;34m(self, kind, X, y, use_scaler, use_scaler_target, cardinality_threshold, cardinality_threshold_target, n_topics, n_topics_target, multilabel, embedding, use_ngrams, ngram_range, max_df, min_df, min_words, model_name, impute, n_quantiles, output_distribution, quantile_range, n_bins, encode, strategy, similarity, categories, keep_n_decimals, remove_node_column, inplace, feature_engine, dbscan, min_dist, min_samples, memoize, verbose)\u001b[0m\n\u001b[1;32m   2635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2636\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nodes\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2637\u001b[0;31m             res = res._featurize_nodes(\n\u001b[0m\u001b[1;32m   2638\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2639\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/graphistry/feature_utils.py\u001b[0m in \u001b[0;36m_featurize_nodes\u001b[0;34m(self, X, y, use_scaler, use_scaler_target, cardinality_threshold, cardinality_threshold_target, n_topics, n_topics_target, multilabel, embedding, use_ngrams, ngram_range, max_df, min_df, min_words, model_name, similarity, categories, impute, n_quantiles, output_distribution, quantile_range, n_bins, encode, strategy, keep_n_decimals, remove_node_column, feature_engine, memoize, verbose)\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0;31m# ############################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2150\u001b[0m         \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFastEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_resolved\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_resolved\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"nodes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2151\u001b[0;31m         \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mnfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2152\u001b[0m         \u001b[0;31m# ###########################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/graphistry/feature_utils.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, src, dst, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1824\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1826\u001b[0;31m         res = self._encode(\n\u001b[0m\u001b[1;32m   1827\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/graphistry/feature_utils.py\u001b[0m in \u001b[0;36m_encode\u001b[0;34m(self, df, y, kind, src, dst, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1768\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1769\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nodes\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1770\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_nodes_dataframes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1771\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"edges\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m             res = process_edge_dataframes(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/graphistry/feature_utils.py\u001b[0m in \u001b[0;36mprocess_nodes_dataframes\u001b[0;34m(df, y, cardinality_threshold, cardinality_threshold_target, n_topics, n_topics_target, use_scaler, use_scaler_target, multilabel, embedding, use_ngrams, ngram_range, max_df, min_df, min_words, model_name, similarity, categories, impute, n_quantiles, output_distribution, quantile_range, n_bins, encode, strategy, keep_n_decimals, feature_engine)\u001b[0m\n\u001b[1;32m   1211\u001b[0m     \u001b[0mother_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m     X_enc, y_enc, data_encoder, label_encoder = process_dirty_dataframes(\n\u001b[0m\u001b[1;32m   1214\u001b[0m         \u001b[0mother_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/graphistry/feature_utils.py\u001b[0m in \u001b[0;36mprocess_dirty_dataframes\u001b[0;34m(ndf, y, cardinality_threshold, cardinality_threshold_target, n_topics, n_topics_target, similarity, categories, multilabel, feature_engine)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\":: Encoding DataFrame might take a few minutes ------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m         \u001b[0mX_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m         \u001b[0mX_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_enc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/cuml/internals/api_decorators.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recreate_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/cu_cat/_table_vectorizer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_cast\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_auto_cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0;31m# Select columns by dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/cu_cat/_table_vectorizer.py\u001b[0m in \u001b[0;36m_auto_cast\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;31m# because the former tends to raise all kind of issues when dealing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0;31m# with scikit-learn (as of version 0.24).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0m_has_missing_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m## cannot iterate on cudf.Series so any cannot count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m                 \u001b[0;31m# Some numerical dtypes like Int64 or Float64 only support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;31m# pd.NA, so they must be converted to np.float64 before.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5900\u001b[0m         ):\n\u001b[1;32m   5901\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5902\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5904\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'to_pandas'"
          ]
        }
      ],
      "source": [
        "# bench=pd.DataFrame(columns=['dataset','row','col','cc_time','dc_time'])\n",
        "# !wget -nc https://www.dropbox.com/s/31dx1g6g59exoc3/part.88.parquet\n",
        "\n",
        "# winlogsA=pd.read_parquet('part.88.parquet')\n",
        "# n=[1000,5000,10000,50000,100000] #,1000000]\n",
        "# for p in np.arange(X):\n",
        "\n",
        "  # for ii,i in enumerate(n):\n",
        "\n",
        "winlogs=winlogsA.sample(5000,replace=False)#.iloc[:,:3]\n",
        "winlogs=winlogs.dropna(how='any',axis=1)\n",
        "# winlogs.shape\n",
        "g = graphistry.nodes(cudf.from_pandas(winlogs))\n",
        "\n",
        "t=time()\n",
        "# for jj,j in enumerate(['cu_cat','dirty_cat']):\n",
        "g.featurize(feature_engine='dirty_cat',memoize=False)\n",
        "t1=time()-t\n",
        "\n",
        "#     g = graphistry.nodes(winlogs)\n",
        "#     t=time()\n",
        "#     # for jj,j in enumerate(['cu_cat','']):\n",
        "#     g.featurize(feature_engine='dirty_cat',memoize=False)\n",
        "#     t2=time()-t\n",
        "    \n",
        "#     bench.loc[1+bench.shape[0]]=['winlogs',i,winlogs.shape[1],t1,t2]\n",
        "#     bench.to_csv('winlogs_bench.txt',sep='\\t',mode='a')\n",
        "# !cp *.txt /content/drive/MyDrive/graphistry"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "winlogsA=pd.read_parquet('part.88.parquet')\n",
        "\n",
        "winlogs=winlogsA.sample(10000,replace=False)#.iloc[:,:3]\n",
        "winlogs=winlogs.dropna(how='any',axis=1)\n",
        "\n",
        "g = graphistry.nodes(cudf.from_pandas(winlogs))\n",
        "# g=g.featurize(feature_engine='cu_cat',memoize=False)\n",
        "g2=g.umap(feature_engine='cu_cat')"
      ],
      "metadata": {
        "id": "nOf-nmFyGSth"
      },
      "id": "nOf-nmFyGSth",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g2.plot()"
      ],
      "metadata": {
        "id": "utOACkq4HqVL"
      },
      "id": "utOACkq4HqVL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad3a97e1-9168-4e08-9217-363a03998c6b",
      "metadata": {
        "id": "ad3a97e1-9168-4e08-9217-363a03998c6b"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "# newsgroups = fetch_20newsgroups()#categories=categories)\n",
        "n = [500]\n",
        "for p in np.arange(X):\n",
        "\n",
        "  for ii,i in enumerate(n):\n",
        "    \n",
        "    newsA, _ = fetch_20newsgroups(\n",
        "        shuffle=True,\n",
        "        random_state=1,\n",
        "        remove=(\"headers\", \"footers\", \"quotes\"),\n",
        "        return_X_y=True,\n",
        "    )\n",
        "\n",
        "    news = newsA[:i]\n",
        "    news=pd.DataFrame(news)\n",
        "    # newsA=pd.DataFrame(newsA)\n",
        "    \n",
        "    g = graphistry.nodes(cudf.from_pandas(news))\n",
        "    t=time()\n",
        "    g2 = g.umap(feature_engine='cu_cat',memoize=False)\n",
        "    t1=time()-t\n",
        "\n",
        "\n",
        "    g = graphistry.nodes(news)\n",
        "    t=time()\n",
        "    g2 = g.umap(feature_engine='dirty_cat',memoize=False)\n",
        "    t2=time()-t\n",
        "\n",
        "    bench.loc[1+bench.shape[0]]=['20news',i,news.shape[1],t1,t2]\n",
        "!cp *.txt /content/drive/MyDrive/graphistry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cba7849e-6094-45f5-9581-8fcdddeefe8c",
      "metadata": {
        "id": "cba7849e-6094-45f5-9581-8fcdddeefe8c"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('https://gist.githubusercontent.com/silkspace/c7b50d0c03dc59f63c48d68d696958ff/raw/31d918267f86f8252d42d2e9597ba6fc03fcdac2/redteam_50k.csv', index_col=0)\n",
        "red_team = pd.read_csv('https://gist.githubusercontent.com/silkspace/5cf5a94b9ac4b4ffe38904f20d93edb1/raw/888dabd86f88ea747cf9ff5f6c44725e21536465/redteam_labels.csv', index_col=0)\n",
        "df['feats'] = df.src_computer + ' ' + df.dst_computer + ' ' + df.auth_type + ' ' + df.logontype\n",
        "df['feats2'] = df.src_computer + ' ' + df.dst_computer\n",
        "ndf = df.drop_duplicates(subset=['feats'])\n",
        "tdf = pd.concat([red_team.reset_index(), ndf.reset_index()])\n",
        "tdf['node'] = range(len(tdf))\n",
        "for p in np.arange(X):\n",
        "\n",
        "  t=time()\n",
        "  g5 = graphistry.nodes((tdf))\n",
        "  g5.umap(X=['feats'], feature_engine='cu_cat',memoize=False)\n",
        "  t1=time()-t\n",
        "\n",
        "  t=time()\n",
        "  g5 = graphistry.nodes((tdf))\n",
        "  g5.umap(X=['feats'], feature_engine='dirty_cat',memoize=False)\n",
        "  t2=time()-t\n",
        "  bench.loc[1+bench.shape[0]]=['redteam',i,news.shape[1],t1,t2]\n",
        "  bench.to_csv('redteam_bench.txt',sep='\\t',mode='a')\n",
        "!cp *.txt /content/drive/MyDrive/graphistry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6586ccf1-5feb-48f7-aba0-674e6068e298",
      "metadata": {
        "id": "6586ccf1-5feb-48f7-aba0-674e6068e298"
      },
      "outputs": [],
      "source": [
        "edf = pd.read_csv('https://gist.githubusercontent.com/silkspace/33bde3e69ae24fee1298a66d1e00b467/raw/dc66bd6f1687270be7098f94b3929d6a055b4438/malware_bots.csv', index_col=0)\n",
        "T = edf.Label.apply(lambda x: True if 'Botnet' in x else False)\n",
        "bot = edf[T]\n",
        "nbot = edf[~T]\n",
        "print(f'Botnet abundance: {100*len(bot)/len(edf):0.2f}%')# so botnet traffic makes up a tiny fraction of total\n",
        "\n",
        "# let's balance the dataset in a 10-1 ratio, for speed and demonstrative purposes\n",
        "negs = nbot.sample(10*len(bot))\n",
        "edf = pd.concat([bot, negs])  # top part of arrays are bot traffic, then all non-bot traffic\n",
        "edf = edf.drop_duplicates()\n",
        "\n",
        "# some useful indicators for later that predict Botnet as Bool and Int\n",
        "Y = edf.Label.apply(lambda x: 1 if 'Botnet' in x else 0)  # np.array(T)\n",
        "\n",
        "# Later we will use and exploit any meaning shared between the labels in a latent distribution\n",
        "\n",
        "# add it to the dataframe\n",
        "edf['bot'] = Y\n",
        "\n",
        "# name some columns for edges and features\n",
        "src = 'SrcAddr'\n",
        "dst = 'DstAddr'\n",
        "good_cols_with_edges = ['Dur', 'Proto', 'Sport',\n",
        "       'Dport', 'State','TotBytes', 'SrcBytes', src, dst]\n",
        "\n",
        "good_cols_without_edges = ['Dur', 'Proto', 'Sport',\n",
        "       'Dport', 'State', 'TotPkts', 'TotBytes', 'SrcBytes']\n",
        "\n",
        "## some encoding parameters\n",
        "n_topics = 20\n",
        "n_topics_target = 7\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "229b2021-cbea-49fa-8ba9-1aea89e7017e",
      "metadata": {
        "id": "229b2021-cbea-49fa-8ba9-1aea89e7017e"
      },
      "outputs": [],
      "source": [
        "for p in np.arange(X):\n",
        "\n",
        "  t=time()\n",
        "  g = graphistry.edges(cudf.from_pandas(edf), src, dst)\n",
        "\n",
        "  g1a = g.featurize(kind='edges', \n",
        "              X=good_cols_with_edges, \n",
        "              y = ['bot'], \n",
        "              # use_scaler='quantile',\n",
        "              # use_scaler_target=None,\n",
        "              cardinality_threshold=20,\n",
        "              cardinality_threshold_target=2, \n",
        "              n_topics=n_topics,\n",
        "              feature_engine='cu_cat',\n",
        "              # engine='cuml',\n",
        "              memoize=False,\n",
        "              n_topics_target=n_topics_target,\n",
        "              n_bins=n_topics_target,\n",
        "              # metric='euclidean', \n",
        "              # n_neighbors=12)\n",
        "                  )\n",
        "  t1=time()-t\n",
        "\n",
        "  t=time()\n",
        "  g = graphistry.edges((edf), src, dst)\n",
        "\n",
        "  g1a = g.featurize(kind='edges', \n",
        "              X=good_cols_with_edges, \n",
        "              y = ['bot'], \n",
        "              # use_scaler='quantile',\n",
        "              # use_scaler_target=None,\n",
        "              cardinality_threshold=20,\n",
        "              cardinality_threshold_target=2, \n",
        "              n_topics=n_topics,\n",
        "              feature_engine='dirty_cat',\n",
        "              # engine='cuml',\n",
        "              memoize=False,\n",
        "              n_topics_target=n_topics_target,\n",
        "              n_bins=n_topics_target,\n",
        "              # metric='euclidean', \n",
        "              # n_neighbors=12)\n",
        "                  )\n",
        "  t2=time()-t\n",
        "\n",
        "  bench.loc[bench.shape[0]+1]=['ctu13',i,news.shape[1],t1,t2]\n",
        "  bench.to_csv('ctu_bench.txt',sep='\\t',mode='a')\n",
        "!cp *.txt /content/drive/MyDrive/graphistry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a8b11c6-5367-412e-8ceb-8113636cab72",
      "metadata": {
        "id": "7a8b11c6-5367-412e-8ceb-8113636cab72"
      },
      "outputs": [],
      "source": [
        "dfA = pd.read_csv('https://storage.googleapis.com/cohere-assets/blog/text-clustering/data/askhn3k_df.csv', index_col=0)\n",
        "for p in np.arange(X):\n",
        "\n",
        "  n=[1000,2000,2999] #,1000000]\n",
        "  for ii,i in enumerate(n):\n",
        "      df = dfA.sample(i,replace=False) # set smaller if you want to test a minibatch \n",
        "\n",
        "      g = graphistry.nodes(cudf.from_pandas(df))\n",
        "\n",
        "\n",
        "      t=time()\n",
        "      g2 = g.featurize(X=['title', 'text'], # the features to encode (can add/remove 'text', etc)\n",
        "                      y=['score'], # for demonstrative purposes, we include a target -- though this one is not really conditioned on textual features in a straightforward way\n",
        "                      model_name='msmarco-distilbert-base-v2', #'paraphrase-MiniLM-L6-v2', etc, from sbert/Huggingface, the text encoding model\n",
        "                      min_words = 0, # when 0 forces all X=[..] as textually encoded, higher values would ascertain if a column is textual or not depending on average number of words per column\n",
        "                      use_ngrams=False, # set to True if you want ngram features instead (does not make great plots but useful for other situations)\n",
        "                      # use_scaler_target='zscale', # for regressive targets\n",
        "                      # use_scaler=None, # there are many more settings see `g.featurize?` and `g.umap?` for further options\n",
        "                      feature_engine='cu_cat',\n",
        "                      memoize=False,    \n",
        "                    )\n",
        "      t1=time()-t\n",
        "      \n",
        "      \n",
        "      t=time()\n",
        "      g2 = g.featurize(X=['title', 'text'], # the features to encode (can add/remove 'text', etc)\n",
        "                      y=['score'], # for demonstrative purposes, we include a target -- though this one is not really conditioned on textual features in a straightforward way\n",
        "                      model_name='msmarco-distilbert-base-v2', #'paraphrase-MiniLM-L6-v2', etc, from sbert/Huggingface, the text encoding model\n",
        "                      min_words = 0, # when 0 forces all X=[..] as textually encoded, higher values would ascertain if a column is textual or not depending on average number of words per column\n",
        "                      use_ngrams=False, # set to True if you want ngram features instead (does not make great plots but useful for other situations)\n",
        "                      # use_scaler_target='zscale', # for regressive targets\n",
        "                      # use_scaler=None, # there are many more settings see `g.featurize?` and `g.umap?` for further options\n",
        "                      feature_engine='dirty_cat',\n",
        "                      memoize=False,    \n",
        "                    )\n",
        "      t2=time()-t\n",
        "      \n",
        "      bench.loc[bench.shape[0]+1]=['askHN',i,news.shape[1],t1,t2]\n",
        "      bench.to_csv('askHN_bench.txt',sep='\\t',mode='a')\n",
        "  !cp *.txt /content/drive/MyDrive/graphistry"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# winlogsA=pd.read_parquet('part.88.parquet')\n",
        "for p in np.arange(X):\n",
        "\n",
        "  i=1000000\n",
        "\n",
        "  winlogs=winlogsA.sample(i,replace=False)#.iloc[:,:3]\n",
        "  winlogs=winlogs.dropna(how='any',axis=1)\n",
        "  # winlogs.shape\n",
        "  g = graphistry.nodes(cudf.from_pandas(winlogs))\n",
        "\n",
        "  t=time()\n",
        "  # for jj,j in enumerate(['cu_cat','dirty_cat']):\n",
        "  g.featurize(feature_engine='cu_cat',memoize=False)\n",
        "  t1=time()-t\n",
        "\n",
        "  t2=np.nan\n",
        "  bench.loc[ii]=['winlogs',winlogs.shape[0],winlogs.shape[1],t1,t2]\n",
        "  bench.to_csv('1m_winlogs_bench.txt',sep='\\t',mode='a')\n",
        "!cp *.txt /content/drive/MyDrive/graphistry"
      ],
      "metadata": {
        "id": "5mSr1YJy8a_m"
      },
      "id": "5mSr1YJy8a_m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bench.to_csv('bench.txt',sep='\\t')"
      ],
      "metadata": {
        "id": "m_juiut3131f"
      },
      "id": "m_juiut3131f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp *.txt /content/drive/MyDrive/graphistry"
      ],
      "metadata": {
        "id": "JVZpeZdn133s"
      },
      "id": "JVZpeZdn133s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tQ2iEPAX-dMo"
      },
      "id": "tQ2iEPAX-dMo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# run as script"
      ],
      "metadata": {
        "id": "poLK-68Y-lFB"
      },
      "id": "poLK-68Y-lFB"
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "    ### WINLOGS\n",
        "    # !wget -nc https://www.dropbox.com/s/31dx1g6g59exoc3/part.88.parquet\n",
        "\n",
        "    winlogsA=pd.read_parquet('part.88.parquet')\n",
        "\n",
        "    ### 20NEWS ###\n",
        "    # from sklearn.datasets import fetch_20newsgroups\n",
        "    # newsgroups = fetch_20newsgroups()#categories=categories)\n",
        "\n",
        "    ### REDTEAM ###\n",
        "    df = pd.read_csv('https://gist.githubusercontent.com/silkspace/c7b50d0c03dc59f63c48d68d696958ff/raw/31d918267f86f8252d42d2e9597ba6fc03fcdac2/redteam_50k.csv', index_col=0)\n",
        "    red_team = pd.read_csv('https://gist.githubusercontent.com/silkspace/5cf5a94b9ac4b4ffe38904f20d93edb1/raw/888dabd86f88ea747cf9ff5f6c44725e21536465/redteam_labels.csv', index_col=0)\n",
        "    df['feats'] = df.src_computer + ' ' + df.dst_computer + ' ' + df.auth_type + ' ' + df.logontype\n",
        "    df['feats2'] = df.src_computer + ' ' + df.dst_computer\n",
        "    ndf = df.drop_duplicates(subset=['feats'])\n",
        "    tdf = pd.concat([red_team.reset_index(), ndf.reset_index()])\n",
        "    tdf['node'] = range(len(tdf))\n",
        "\n",
        "\n",
        "    ### CTU13 ###\n",
        "    edf = pd.read_csv('https://gist.githubusercontent.com/silkspace/33bde3e69ae24fee1298a66d1e00b467/raw/dc66bd6f1687270be7098f94b3929d6a055b4438/malware_bots.csv', index_col=0)\n",
        "    T = edf.Label.apply(lambda x: True if 'Botnet' in x else False)\n",
        "    bot = edf[T]\n",
        "    nbot = edf[~T]\n",
        "    print(f'Botnet abundance: {100*len(bot)/len(edf):0.2f}%')# so botnet traffic makes up a tiny fraction of total\n",
        "\n",
        "    # let's balance the dataset in a 10-1 ratio, for speed and demonstrative purposes\n",
        "    negs = nbot.sample(10*len(bot))\n",
        "    edf = pd.concat([bot, negs])  # top part of arrays are bot traffic, then all non-bot traffic\n",
        "    edf = edf.drop_duplicates()\n",
        "\n",
        "    # some useful indicators for later that predict Botnet as Bool and Int\n",
        "    Y = edf.Label.apply(lambda x: 1 if 'Botnet' in x else 0)  # np.array(T)\n",
        "\n",
        "    # Later we will use and exploit any meaning shared between the labels in a latent distribution\n",
        "\n",
        "    # add it to the dataframe\n",
        "    edf['bot'] = Y\n",
        "\n",
        "    # name some columns for edges and features\n",
        "    src = 'SrcAddr'\n",
        "    dst = 'DstAddr'\n",
        "    good_cols_with_edges = ['Dur', 'Proto', 'Sport',\n",
        "        'Dport', 'State','TotBytes', 'SrcBytes', src, dst]\n",
        "\n",
        "    good_cols_without_edges = ['Dur', 'Proto', 'Sport',\n",
        "        'Dport', 'State', 'TotPkts', 'TotBytes', 'SrcBytes']\n",
        "\n",
        "    ## some encoding parameters\n",
        "    n_topics = 20\n",
        "    n_topics_target = 7\n",
        "\n",
        "    ### ASKHN ###\n",
        "    dfA = pd.read_csv('https://storage.googleapis.com/cohere-assets/blog/text-clustering/data/askhn3k_df.csv', index_col=0)\n",
        "\n",
        "    # nn=[1000,2000,2999] #,1000000]\n",
        "    return winlogsA,tdf,edf,dfA"
      ],
      "metadata": {
        "id": "oYWs0l_T-dPI"
      },
      "id": "oYWs0l_T-dPI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_bench(X,winlogsA,tdf,edf,dfA):\n",
        "    nn = [500]\n",
        "    import time\n",
        "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    from time import time\n",
        "    from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "    bench=pd.DataFrame(columns=['dataset','row','col','cc_time','dc_time'])\n",
        "    for p in np.arange(X):\n",
        "        n=[1000,5000,10000,50000,100000] #,1000000]\n",
        "        for ii,i in enumerate(n):\n",
        "\n",
        "            winlogs=winlogsA.sample(i,replace=False)#.iloc[:,:3]\n",
        "            winlogs=winlogs.dropna(how='any',axis=1)\n",
        "            # winlogs.shape\n",
        "            g = graphistry.nodes(cudf.from_pandas(winlogs))\n",
        "\n",
        "            t=time()\n",
        "            # for jj,j in enumerate(['cu_cat','dirty_cat']):\n",
        "            g.featurize(feature_engine='cu_cat',memoize=False)\n",
        "            t1=time()-t\n",
        "\n",
        "            g = graphistry.nodes(winlogs)\n",
        "            t=time()\n",
        "            # for jj,j in enumerate(['cu_cat','']):\n",
        "            g.featurize(feature_engine='dirty_cat',memoize=False)\n",
        "            t2=time()-t\n",
        "\n",
        "            bench.loc[ii]=['winlogs',i,winlogs.shape[1],t1,t2]\n",
        "            del g\n",
        "\n",
        "\n",
        "        for ii,i in enumerate(nn):\n",
        "\n",
        "            newsA, _ = fetch_20newsgroups(\n",
        "                shuffle=True,\n",
        "                random_state=1,\n",
        "                remove=(\"headers\", \"footers\", \"quotes\"),\n",
        "                return_X_y=True,\n",
        "            )\n",
        "\n",
        "            news = newsA[:i]\n",
        "            news=pd.DataFrame(news)\n",
        "            # newsA=pd.DataFrame(newsA)\n",
        "\n",
        "            g = graphistry.nodes(cudf.from_pandas(news))\n",
        "            t=time()\n",
        "            g.umap(feature_engine='cu_cat',memoize=False)\n",
        "            t1=time()-t\n",
        "\n",
        "\n",
        "            g = graphistry.nodes(news)\n",
        "            t=time()\n",
        "            g.umap(feature_engine='dirty_cat',memoize=False)\n",
        "            t2=time()-t\n",
        "\n",
        "            bench.loc[1+bench.shape[0]]=['20news',i,news.shape[1],t1,t2]\n",
        "            del g\n",
        "\n",
        "\n",
        "        t=time()\n",
        "        g5 = graphistry.nodes((tdf))\n",
        "        g5.umap(X=['feats'], feature_engine='cu_cat',memoize=False)\n",
        "        t1=time()-t\n",
        "\n",
        "        t=time()\n",
        "        g5 = graphistry.nodes((tdf))\n",
        "        g5.umap(X=['feats'], feature_engine='dirty_cat',memoize=False)\n",
        "        t2=time()-t\n",
        "        bench.loc[1+bench.shape[0]]=['redteam',i,news.shape[1],t1,t2]\n",
        "        del g5\n",
        "\n",
        "\n",
        "        src = 'SrcAddr'\n",
        "        dst = 'DstAddr'\n",
        "        good_cols_with_edges = ['Dur', 'Proto', 'Sport',\n",
        "              'Dport', 'State','TotBytes', 'SrcBytes', src, dst]\n",
        "\n",
        "        good_cols_without_edges = ['Dur', 'Proto', 'Sport',\n",
        "              'Dport', 'State', 'TotPkts', 'TotBytes', 'SrcBytes']\n",
        "        n_topics = 20\n",
        "        n_topics_target = 7\n",
        "\n",
        "        t=time()\n",
        "        g = graphistry.edges(cudf.from_pandas(edf), src, dst)\n",
        "\n",
        "        g.featurize(kind='edges', \n",
        "                    X=good_cols_with_edges, \n",
        "                    y = ['bot'], \n",
        "                    # use_scaler='quantile',\n",
        "                    # use_scaler_target=None,\n",
        "                    cardinality_threshold=20,\n",
        "                    cardinality_threshold_target=2, \n",
        "                    n_topics=n_topics,\n",
        "                    feature_engine='cu_cat',\n",
        "                    # engine='cuml',\n",
        "                    memoize=False,\n",
        "                    n_topics_target=n_topics_target,\n",
        "                    n_bins=n_topics_target,\n",
        "                    # metric='euclidean', \n",
        "                    # n_neighbors=12)\n",
        "                        )\n",
        "        t1=time()-t\n",
        "\n",
        "        t=time()\n",
        "        g = graphistry.edges((edf), src, dst)\n",
        "\n",
        "        g.featurize(kind='edges', \n",
        "                    X=good_cols_with_edges, \n",
        "                    y = ['bot'], \n",
        "                    # use_scaler='quantile',\n",
        "                    # use_scaler_target=None,\n",
        "                    cardinality_threshold=20,\n",
        "                    cardinality_threshold_target=2, \n",
        "                    n_topics=n_topics,\n",
        "                    feature_engine='dirty_cat',\n",
        "                    # engine='cuml',\n",
        "                    memoize=False,\n",
        "                    n_topics_target=n_topics_target,\n",
        "                    n_bins=n_topics_target,\n",
        "                    # metric='euclidean', \n",
        "                    # n_neighbors=12)\n",
        "                        )\n",
        "        t2=time()-t\n",
        "\n",
        "        bench.loc[bench.shape[0]+1]=['ctu13',i,news.shape[1],t1,t2]\n",
        "        del g\n",
        "\n",
        "        nn=[1000,2000,2999] #,1000000]\n",
        "        for ii,i in enumerate(nn):\n",
        "            df = dfA.sample(i,replace=False) # set smaller if you want to test a minibatch \n",
        "\n",
        "            g = graphistry.nodes(cudf.from_pandas(df))\n",
        "\n",
        "\n",
        "            t=time()\n",
        "            g.featurize(X=['title', 'text'], # the features to encode (can add/remove 'text', etc)\n",
        "                            y=['score'], # for demonstrative purposes, we include a target -- though this one is not really conditioned on textual features in a straightforward way\n",
        "                            model_name='msmarco-distilbert-base-v2', #'paraphrase-MiniLM-L6-v2', etc, from sbert/Huggingface, the text encoding model\n",
        "                            min_words = 0, # when 0 forces all X=[..] as textually encoded, higher values would ascertain if a column is textual or not depending on average number of words per column\n",
        "                            use_ngrams=False, # set to True if you want ngram features instead (does not make great plots but useful for other situations)\n",
        "                            # use_scaler_target='zscale', # for regressive targets\n",
        "                            # use_scaler=None, # there are many more settings see `g.featurize?` and `g.umap?` for further options\n",
        "                            feature_engine='cu_cat',\n",
        "                            memoize=False,    \n",
        "                          )\n",
        "            t1=time()-t\n",
        "\n",
        "\n",
        "            t=time()\n",
        "            g.featurize(X=['title', 'text'], # the features to encode (can add/remove 'text', etc)\n",
        "                            y=['score'], # for demonstrative purposes, we include a target -- though this one is not really conditioned on textual features in a straightforward way\n",
        "                            model_name='msmarco-distilbert-base-v2', #'paraphrase-MiniLM-L6-v2', etc, from sbert/Huggingface, the text encoding model\n",
        "                            min_words = 0, # when 0 forces all X=[..] as textually encoded, higher values would ascertain if a column is textual or not depending on average number of words per column\n",
        "                            use_ngrams=False, # set to True if you want ngram features instead (does not make great plots but useful for other situations)\n",
        "                            # use_scaler_target='zscale', # for regressive targets\n",
        "                            # use_scaler=None, # there are many more settings see `g.featurize?` and `g.umap?` for further options\n",
        "                            feature_engine='dirty_cat',\n",
        "                            memoize=False,    \n",
        "                          )\n",
        "            t2=time()-t\n",
        "\n",
        "            bench.loc[bench.shape[0]+1]=['askHN',i,news.shape[1],t1,t2]\n",
        "            del g\n",
        "\n",
        "        # winlogsA=pd.read_parquet('part.88.parquet')\n",
        "        i=1000000\n",
        "\n",
        "        winlogs=winlogsA.sample(i,replace=False)#.iloc[:,:3]\n",
        "        winlogs=winlogs.dropna(how='any',axis=1)\n",
        "        # winlogs.shape\n",
        "        g = graphistry.nodes(cudf.from_pandas(winlogs))\n",
        "\n",
        "        t=time()\n",
        "        # for jj,j in enumerate(['cu_cat','dirty_cat']):\n",
        "        g.featurize(feature_engine='cu_cat',memoize=False)\n",
        "        t1=time()-t\n",
        "\n",
        "        t2=np.nan\n",
        "        bench.loc[ii]=['winlogs',winlogs.shape[0],winlogs.shape[1],t1,t2]\n",
        "\n",
        "        bench.to_csv('bench'+timestr+'.txt',sep='\\t',mode='a')\n",
        "        del g"
      ],
      "metadata": {
        "id": "W6HTbldd-fEw"
      },
      "id": "W6HTbldd-fEw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "winlogsA,tdf,edf,dfA=load_data()\n",
        "run_bench(1,winlogsA,tdf,edf,dfA)"
      ],
      "metadata": {
        "id": "ZWZ81ZTi-fp9"
      },
      "id": "ZWZ81ZTi-fp9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7VzRYIAQ-nDD"
      },
      "id": "7VzRYIAQ-nDD",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "nLOETLTC-vhr"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}