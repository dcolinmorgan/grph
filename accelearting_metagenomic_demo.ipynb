{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dcolinmorgan/grph/blob/main/accelearting_metagenomic_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accelerating metagenomic analysis with [Graphistry](graphistry.com)"
      ],
      "metadata": {
        "id": "ozrca88hza85"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using GPU-accelerated UMAP + DBScan analysis & visualization, metagenomic samples can be compared faster and much more easily explored.\n",
        "\n",
        "*   Task: Analyze metagenomic samples for similarity\n",
        "*   Data: time series samples\n",
        "**   563 samples collected from 84 donors, producing 4 dense long-term time series (up to 1 sample every other day during 18 months)\n",
        "*   [data](https://www.ebi.ac.uk/ena/browser/view/PRJNA544527)\n",
        "*   [metadata](https://static-content.springer.com/esm/art%3A10.1038%2Fs41591-019-0559-3/MediaObjects/41591_2019_559_MOESM3_ESM.xlsx)\n",
        "*   [paper](https://www-nature-com.eproxy.lib.hku.hk/articles/s41591-019-0559-3)\n",
        "\n",
        "\n",
        "**Insight/ Result:**\n",
        "\n",
        "43s to umap and dbscan vs 2342s here\n",
        "over **50X** faster for a single run, and since [the reference paper for this analysis](https://journals.asm.org/doi/full/10.1128/msystems.00118-23) runs this analysis 12x per dataset (here we only have 1 dataset), we could expect to save nearly the entire 8hrs for this dataset, taking less than 10 minutes in total\n",
        "\n",
        "(See also: [CPU baseline](https://github.com/dcolinmorgan/grph/blob/main/accelerating_chemical_mappings.ipynb))"
      ],
      "metadata": {
        "id": "tLRHg2VEzoYy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjnS_PCWaClg"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTzHVRgEcDUV"
      },
      "outputs": [],
      "source": [
        "!pip install --extra-index-url=https://pypi.nvidia.com cuml-cu11 cudf-cu11 cugraph-cu11 pylibraft_cu11 raft_dask_cu11 dask_cudf_cu11 pylibcugraph_cu11 pylibraft_cu11\n",
        "import cuml,cudf\n",
        "print(cuml.__version__)\n",
        "\n",
        "!pip install -U --force git+https://github.com/graphistry/pygraphistry.git@cudf\n",
        "!pip install -U git+https://github.com/graphistry/cu-cat.git@DT3\n",
        "# !pip install dirty_cat\n",
        "\n",
        "!pip install Biopython\n",
        "\n",
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "Ob5QrPuiAf-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# import /configure\n",
        "\n",
        "get a free api-key at https://www.graphistry.com/\n"
      ],
      "metadata": {
        "id": "HK_8_7UB0mhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import graphistry\n",
        "from time import time\n",
        "import cuml,cudf\n",
        "print(cuml.__version__)\n",
        "\n",
        "graphistry.register(api=3,protocol=\"https\", server=\"hub.graphistry.com\", username='dcolinmorgan', password='fXjJnkE3Gik6BWy') ## key id, secret key\n",
        "\n",
        "# graphistry.register(api=3,protocol=\"https\", server=\"hub.graphistry.com\", username='dcolinmorgan', password='***') ## key id, secret key\n",
        "graphistry.__version__"
      ],
      "metadata": {
        "id": "i42QrQ_ejC4h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "9977c755-bc92-42b7-bffc-64bed2c904e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23.06.00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.28.7+463.gfb96400'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t7pJBbPYDZwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KT6k29iIDaDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# bio-ml dataset\n",
        "\n",
        "\n",
        "1.   [3 subjects x 10 time points](\n",
        "https://www.ebi.ac.uk/ena/browser/view/PRJNA544527)\n",
        "\n",
        "2.  [metadata](\n",
        "https://static-content.springer.com/esm/art%3A10.1038%2Fs41591-019-0559-3/MediaObjects/41591_2019_559_MOESM3_ESM.xlsx)\n",
        "\n",
        "3.   !wget https://raw.githubusercontent.com/dcolinmorgan/grph/main/ftp_PRJNA544527.txt\n"
      ],
      "metadata": {
        "id": "_Y1VlCGy4_FR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR922/006/SRR9224006/SRR9224006_1.fastq.gz\n",
        "!wget -nc ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR922/006/SRR9224006/SRR9224006_2.fastq.gz"
      ],
      "metadata": {
        "id": "CBN6Z_77Sduq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! gunzip SRR9224006_1.fastq.gz\n",
        "! gunzip SRR9224006_2.fastq.gz"
      ],
      "metadata": {
        "id": "UjbF1ZfwULLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head /content/SRR9224006_1.fastq"
      ],
      "metadata": {
        "id": "ljJnoNeLSnWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio import SeqIO\n",
        "import glob,os\n",
        "import pandas as pd\n",
        "B=pd.DataFrame()\n",
        "for i in glob.glob('/content/*.fastq'):\n",
        "    # j=os.path.basename(i)\n",
        "    fasta_sequences = SeqIO.parse(open(i),'fastq')\n",
        "    identifiers = []\n",
        "    sequences = []\n",
        "    for fasta in fasta_sequences:\n",
        "        name, sequence = fasta.id, str(fasta.seq)\n",
        "        identifiers.append(name)\n",
        "        sequences.append(sequence)\n",
        "\n",
        "    A=pd.DataFrame([identifiers,sequences]).T\n",
        "    A.columns=['ID','seq']\n",
        "    A.dropna(inplace=True)\n",
        "    B=B.append(A)\n",
        "    # A['ID']#=A.ID.str.split('-')[0:1]\n",
        "# B['ID']=B['ID'].str.split('-').str[0]+'_'+B['ID'].str.split('-').str[1]#.cat()\n",
        "B['ID']=B.ID.str.split('_length').str[0]\n",
        "B.index=B.ID"
      ],
      "metadata": {
        "id": "UWDGFCWxSpv_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c6fef3c-9cc8-4fa9-afa1-e24c3b77149d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-457fd4362762>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mBio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSeqIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/*.fastq'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Bio'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# install [HUMAnN 3](https://huttenhower.sph.harvard.edu/humann), a method for efficiently and accurately profiling the abundance of microbial metabolic pathways and other molecular functions from metagenomic or metatranscriptomic sequencing data."
      ],
      "metadata": {
        "id": "fDvymRFjHPNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install humann --no-binary :all:\n",
        "!pip install metaphlan"
      ],
      "metadata": {
        "id": "yIeeDXPBHN6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### !humann_databases --download utility_mapping full /path/to/databases --update-config yes\n",
        "\n",
        "# !humann_test\n",
        "\n",
        "# !wget https://github.com/biobakery/humann/raw/master/examples/demo.fastq.gz\n",
        "# !humann -i demo.fastq.gz -o sample_results"
      ],
      "metadata": {
        "id": "TnYmqPJ-bHPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### takes very long for running all samples\n",
        " (1day+ run on cluster)"
      ],
      "metadata": {
        "id": "gtOG0QeoUoX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir assemble epi_sam_out mpa4_out\n",
        "# !humann -i /content/All_MAGs/Sample_101_S75_bin_1.fa -o test_out\n",
        "%%bash\n",
        "seq=$(ls /content/*.fastq | cut -d / -f2| cut -d _ -f1)\n",
        "\n",
        "for i in $(eval \"echo \"$seq\" | cut -d _ -f1\")\n",
        "\n",
        "do\n",
        "metaphlan /content/${i}.fa --nproc 40 --input_type fasta -o /content/assemble/${i}/h4_out.txt -t rel_ab_w_read_stats\n",
        "done"
      ],
      "metadata": {
        "id": "XAtq7G_waxLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# umap and dbscan\n",
        "\n",
        "idea for metagenomic analysis based on [Quantifying Shared and Unique Gene Content across 17 Microbial Ecosystems\n",
        "](https://journals.asm.org/doi/full/10.1128/msystems.00118-23)\n",
        "\n",
        "(analyze all samples run on cluster)"
      ],
      "metadata": {
        "id": "dHbwBIEn6Wxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sqlalchemy.util.compat import dataclass_fields\n",
        "!wget https://github.com/dcolinmorgan/grph/raw/main/PRJNA544527_mpa4out.txt\n",
        "data=pd.read_csv('/content/PRJNA544527_mpa4out.txt',sep='\\t',skiprows=1,index_col=0)\n",
        "data.index=data.reset_index().clade_name.str.split('|',expand=True)[6]\n",
        "data=data.reset_index().dropna(axis=0)\n",
        "data.index=data[6]\n",
        "data=data.drop(columns=6)\n",
        "\n",
        "!wget https://raw.githubusercontent.com/dcolinmorgan/grph/main/PRJNA544527-meta_inf.txt\n",
        "meta=pd.read_csv('/content/PRJNA544527-meta_inf.txt',sep='\\t',header=None)\n",
        "\n",
        "mm=pd.merge(data.T,meta[[3,5]],left_index=True,right_on=3)\n",
        "\n",
        "mm['id']=mm[5].str.split('-').str[0]\n",
        "mm['time']=mm[5].str.split('_').str[0].str.split('-').str[1]\n",
        "\n",
        "!wget https://static-content.springer.com/esm/art%3A10.1038%2Fs41591-019-0559-3/MediaObjects/41591_2019_559_MOESM3_ESM.xlsx\n",
        "metaa=pd.read_excel('/content/41591_2019_559_MOESM3_ESM.xlsx',sheet_name='SupTable2',skiprows=3)\n",
        "metaa=metaa[['Donor','Age','Sex','BMI']]\n",
        "\n",
        "Full_table=pd.merge(mm,metaa,left_on='id',right_on='Donor')\n",
        "Full_table=Full_table.drop(columns=[3,\t5,\t'id'])\n",
        "# Full_table.time=pd.to_datetime(Full_table.time,unit='d')\n",
        "# Full_table.time=Full_table.time.values.astype('datetime64[M]')\n",
        "\n",
        "data2=Full_table.melt(id_vars=['time','Donor','Age','Sex','BMI'])\n",
        "data2.to_csv('PRJNA544527_mpa4_annot_table.txt',sep='\\t')\n",
        "\n",
        "# final df stored here also\n",
        "# !wget https://raw.githubusercontent.com/dcolinmorgan/grph/main/PRJNA544527_mpa4_annot_table.txt\n",
        "# data2=pd.read_csv('PRJNA544527_mpa4_annot_table.txt',sep='\\t',index_col=0)"
      ],
      "metadata": {
        "id": "RoIBLY3-670T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8_uh77ijR_U",
        "outputId": "bb6f37d2-32d3-4b8d-9779-f42d84658128"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/PRJNA544527_mpa4_annot_table.txt /content/drive/MyDrive/graphistry/metagen_demo/"
      ],
      "metadata": {
        "id": "4savEas1jZyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Zoo17Ui9zxh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a342434-6996-43f2-b3c7-5c448fa43533"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Target is not of type(DataFrame) and has no columns"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Featurizing nodes with feature_engine=cu_cat\n",
            "Using GPU: cu_cat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:! Failed featurize speedup attempt. Continuing without memoization speedups.WARNING:root:Target is not of type(DataFrame) and has no columns"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU: cu_cat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:! Failed umap speedup attempt. Continuing without memoization speedups.WARNING:graphistry.umap_utils:* Ignoring target column of shape (1310040, 0) in UMAP fit, as it is not one dimensional"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "409.20255303382874\n"
          ]
        }
      ],
      "source": [
        "g = graphistry.nodes(cudf.from_pandas(data2[['variable','value']]))\n",
        "\n",
        "t=time()\n",
        "g2=g.featurize(feature_engine='cu_cat',memoize=False)\n",
        "g3=g2.umap(dbscan=True,engine='cuml')\n",
        "print(\"\\n\"+str(time()-t))\n",
        "\n",
        "emb2=g3._node_embedding\n",
        "emb2['time']=data2.time\n",
        "emb2['_n']=data2.variable\n",
        "emb2['index']=data2.variable\n",
        "g22=graphistry.nodes(emb2.reset_index(),'index').edges(g3._edges,'_src_implicit','_dst_implicit').bind(point_x=\"x\",point_y=\"y\").settings(url_params={\"play\":0})\n",
        "##440s"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g22.plot()"
      ],
      "metadata": {
        "id": "8FulqFdJffaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[per the Materials and Methods of our inspirational paper,](https://journals.asm.org/doi/full/10.1128/msystems.00118-23#sec-4)from these (too) many clusters, one can perform cluster-based functional enrichment analysis, cluster-based taxonomoical enrichment analysis and/or identify of ecologically conserved genes and differentially abundant genes"
      ],
      "metadata": {
        "id": "uyUBzVXFAik6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data2=data2[data2.value>0]\n",
        "data2=data2.reset_index(drop = True)\n",
        "data2=data2.drop_duplicates()\n",
        "\n",
        "data2[\"Label\"] = (\n",
        "    data2.groupby(\"Donor\")\n",
        "    .apply(lambda x: x.groupby(\"time\", sort=False).ngroup() + 1)\n",
        "    .values\n",
        ")\n",
        "\n",
        "cc=pd.unique(data2[data2.Label<5].Donor)\n",
        "data2=data2.loc[ data2.Donor.isin(cc), : ]\n",
        "data2=data2[data2.Label<5]\n",
        "\n",
        "data2[\"rank\"] = data2.groupby(\"Donor\")[\"value\"].rank(method=\"dense\", ascending=False)\n",
        "data2=data2[data2['rank']<10.0]\n",
        "\n",
        "\n",
        "grouped = data2.groupby('Donor')\n",
        "def get_next_clus(x): return x['species'].shift(-1)\n",
        "data2[\"next_species\"] = grouped.apply(\n",
        "     lambda x: get_next_clus(x)).reset_index(0, drop=True)\n",
        "grouped = data2.groupby('Donor')\n",
        "\n",
        "  # Working on the Â«nodes_dict\n",
        "\n",
        "data2_spec = list(data2.species.unique())\n",
        "chars = '0123456789ABCDEF'\n",
        "palette=[''+''.join(random.sample(chars,6)) for i in range(len(data2_spec))]\n",
        "output = dict()\n",
        "output.update({'nodes_dict': dict()})\n",
        "i = 0\n",
        "for Label in data2.Label.unique():\n",
        "    output['nodes_dict'].update(\n",
        "        {Label: dict()}\n",
        "    )\n",
        "\n",
        "    data2_spec_at_this_Label = data2[data2['Label'] ==\n",
        "                                   Label]['species'].unique()\n",
        "\n",
        "    Label_palette = []\n",
        "    for spec in data2_spec_at_this_Label:\n",
        "        Label_palette.append(palette[list(data2_spec).index(spec)])\n",
        "\n",
        "    output['nodes_dict'][Label].update(\n",
        "        {\n",
        "            'sources': list(data2_spec_at_this_Label),\n",
        "            'color': Label_palette,\n",
        "            'sources_index': list(range(i, i+len(data2_spec_at_this_Label)))\n",
        "        }\n",
        "    )\n",
        "    i += len(output['nodes_dict'][Label]['sources_index'])\n",
        "\n",
        "\n",
        "  # Working on the links_dict\n",
        "import random\n",
        "output.update({'links_dict': dict()})\n",
        "grouped = data2.groupby(['Donor', 'Label'])\n",
        "\n",
        "def update_source_target(user):\n",
        "    try:\n",
        "\n",
        "        source_index = output['nodes_dict'][user.name[1]]['sources_index'][output['nodes_dict']\n",
        "                                                                           [user.name[1]]['sources'].index(user['species'].values[0])]\n",
        "\n",
        "        target_index = output['nodes_dict'][user.name[1] + 1]['sources_index'][output['nodes_dict']\n",
        "                                                                               [user.name[1] + 1]['sources'].index(user['next_species'].values[0])]\n",
        "\n",
        "         # If this source is already in links_dict...\n",
        "        if source_index in output['links_dict']:\n",
        "            # ...and if this target is already associated to this source...\n",
        "            if target_index in output['links_dict'][source_index]:\n",
        "                # ...then we increment the count of users with this source/target pair by 1\n",
        "                output['links_dict'][source_index][target_index]['value'] += 1\n",
        "            # ...but if the target is not already associated to this source...\n",
        "            else:\n",
        "                # ...we create a new key for this target, for this source, and initiate it with 1 user and the time from source to target\n",
        "                output['links_dict'][source_index].update({target_index:\n",
        "                                                           dict(\n",
        "                                                               {'value': 1}\n",
        "                                                            )\n",
        "                                                           })\n",
        "        # ...but if this source isn't already available in the links_dict, we create its key and the key of this source's target, and we initiate it with 1 user and the time from source to target\n",
        "        else:\n",
        "            output['links_dict'].update({source_index: dict({target_index: dict(\n",
        "                {'value': 1})})})\n",
        "    except Exception as e:\n",
        "        pass\n",
        "\n",
        "grouped.apply(lambda user: update_source_target(user))"
      ],
      "metadata": {
        "id": "IxOeofOKBGho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets = []\n",
        "sources = []\n",
        "values = []\n",
        "\n",
        "for source_key, source_value in output['links_dict'].items():\n",
        "    for target_key, target_value in output['links_dict'][source_key].items():\n",
        "        sources.append(source_key)\n",
        "        targets.append(target_key)\n",
        "        values.append(target_value['value'])\n",
        "\n",
        "labels = []\n",
        "colors = []\n",
        "\n",
        "for key, value in output['nodes_dict'].items():\n",
        "    labels = labels + list(output['nodes_dict'][key]['sources'])\n",
        "    colors = colors + list(output['nodes_dict'][key]['color'])\n",
        "for idx, color in enumerate(colors):\n",
        "    colors[idx] = \"#\" + str(color) + \"\""
      ],
      "metadata": {
        "id": "8kmmLqXSfum0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# label = [\"{} {}\".format(node1_name, node1_val), \"{} {}\".format(node2_name, node2_val) ...]\n",
        "fig = go.Figure(data=[go.Sankey(\n",
        "    node=dict(\n",
        "        thickness=20,  # default is 20\n",
        "        line=dict(color=\"black\", width=0.5),\n",
        "        label=labels,\n",
        "        color=colors\n",
        "    ),\n",
        "    link=dict(\n",
        "        source=sources,\n",
        "        target=targets,\n",
        "        value=values,\n",
        "        hovertemplate='%{value} unique species episodes went from %{source.label} to %{target.label}.',\n",
        "    ))])\n",
        "\n",
        "fig.update_layout(autosize=True, title=dict(text=\"Movement of Top 10 Species During Time Series\", font_size=16), font=dict(size=12, family=\"Arial\"), plot_bgcolor='white')\n",
        "fig.update_layout(\n",
        "    autosize=False,\n",
        "    width=800,\n",
        "    height=800,)"
      ],
      "metadata": {
        "id": "vJhnSN6JfwSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import chart_studio\n",
        "import chart_studio.plotly as py\n",
        "chart_studio.tools.set_credentials_file(username='dcolinmorgan', api_key='***')\n",
        "py.iplot(fig, sharing='public', filename='Meta-time-sankey')"
      ],
      "metadata": {
        "id": "qA9WsOMTfwU-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_Y1VlCGy4_FR"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}