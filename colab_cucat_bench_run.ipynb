{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dcolinmorgan/grph/blob/main/colab_cucat_bench_run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQinzuiQscjc"
      },
      "source": [
        "# cu_cat CPU, GPU benchmark\n",
        "\n",
        "This notebook examines `cu-cat` automatic feature engineering performance on variously populated datasets, ranging in size and complexity of data. The `dirty_cat` engine is highly optimized and parallelized for CPUs, and the `cu-cat` engine further adds single-GPU acceleration.\n",
        "* Advantage can be seen at small scales, but GPU extraction really shines with scale, as GPU memory is loaded close to but not exceeding vram.\n",
        "*The benchmark does not examine bigger-than-memory and distributed scenarios.\n",
        "*There is a tradeoff between compute speedup vs gpu mem swapping time, and some cases are not to the advantage of the GPU.\n",
        "Both the `GapEncoder()` and `TableVectorizer()` methods are employed independently here, as well as more extensively within the framework of `graphistry`'s `.featurize()` and `.umap()` functions.\n",
        "\n",
        "The provided results here are from running on a free Google Colab T4 runtime, with a 2.2GHz Intel CPU (12 GB CPU RAM) and T4 Nvidia GPU (16 GB GPU RAM)."
      ],
      "id": "hQinzuiQscjc"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UC_w5EhksYyX"
      },
      "outputs": [],
      "source": [
        "!pip install --extra-index-url=https://pypi.nvidia.com cuml-cu12 cudf-cu12 #==23.12.00 #cugraph-cu11 pylibraft_cu11 raft_dask_cu11 dask_cudf_cu11 pylibcugraph_cu11 pylibraft_cu11\n",
        "!pip install git+https://github.com/graphistry/pygraphistry.git@dev/depman_gpufeat\n",
        "!pip3 install --upgrade cu_cat"
      ],
      "id": "UC_w5EhksYyX"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zl_CEY3RsZsp",
        "outputId": "ae14a289-a81e-4b31-cdbf-551159a94713"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'24.02.00'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import cuml\n",
        "cuml.__version__"
      ],
      "id": "zl_CEY3RsZsp"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DDkaXicVsbVE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from collections import Counter\n",
        "import cProfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pstats import Stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "import cudf,cuml,cupy"
      ],
      "id": "DDkaXicVsbVE"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4xWbmFMsbSu",
        "outputId": "f278d113-5e5a-4588-e2f2-4aed8cf5be0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "v0.9.11\n"
          ]
        }
      ],
      "source": [
        "import cu_cat\n",
        "print(cu_cat.__version__)"
      ],
      "id": "U4xWbmFMsbSu"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OpgmDTmwsbXX",
        "outputId": "1eb7b377-26d8-4bf5-d072-5064894db7af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.33.0+367.g03f0fc3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import graphistry\n",
        "graphistry.register(api=3,protocol=\"https\", server=\"hub.graphistry.com\", username='dcolinmorgan', password='fXjJnkE3Gik6BWy') ## key id, secret key\n",
        "graphistry.__version__"
      ],
      "id": "OpgmDTmwsbXX"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2wziX0tHsbZu"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "id": "2wziX0tHsbZu"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "QvcZ0QCOsg6o"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "logger = logging.getLogger()\n",
        "logging.basicConfig(level=logging.ERROR, force=True, format='%(asctime)s %(levelname)s %(message)s', datefmt='%H:%M:%S')\n",
        "\n",
        "# logging.basicConfig(filename='app.log',\n",
        "                    # level=logging.DEBUG,\n",
        "                    # force=True, # Resets any previous configuration\n",
        "                    # )"
      ],
      "id": "QvcZ0QCOsg6o"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQC5kLv_76sy",
        "outputId": "2e297e86-7bb6-480f-a1db-16c26c872885"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import cupy as cp\n",
        "cp._default_memory_pool.free_all_blocks()\n",
        "import gc\n",
        "gc.collect()"
      ],
      "id": "JQC5kLv_76sy"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "NFcRO3xeZpLF"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/graphistry/pygraphistry.git\n",
        "# !pip install sentence-transformers umap-learn parameterized dirty_cat\n",
        "# !cd pygraphistry\n",
        "# !git checkout dev/depman_gpufeat\n",
        "\n",
        "!echo PYTHONPATH=\"${PYTHONPATH}:/path/to/directory\" >> .env\n",
        "!echo PYTHONPATH=\"${PYTHONPATH}:graphistry/tests\" >> .env\n",
        "!echo PYTHONPATH=\"${PYTHONPATH}:graphistry\" >> .env\n",
        "# export PYTHONPATH=\"${PYTHONPATH}:graphistry\"\n",
        "# from (del graphistry.)tests.test_feature_utils import\n",
        "# is_test_cudf = cudf # and os.environ[\"TEST_CUDF\"] != \"0\"\n",
        "# !git clone https://github.com/graphistry/cu-cat.git"
      ],
      "id": "NFcRO3xeZpLF"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "SUUJIcP6ZpN6"
      },
      "outputs": [],
      "source": [
        "# !pytest graphistry/tests/test_feature_utils.py\n",
        "# !pytest graphistry/tests/test_umap_utils.py\n",
        "# !pytest graphistry/tests/test_umap_utils.py::TestUMAPFitTransform::test_transform_umap"
      ],
      "id": "SUUJIcP6ZpN6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introducing `cu-cat`\n",
        "### with GPU-accelerated `GapEncoder` and `TableVectorizer` (prev. `SuperVectorizer`)"
      ],
      "metadata": {
        "id": "PVGtSJk3uk-j"
      },
      "id": "PVGtSJk3uk-j"
    },
    {
      "cell_type": "code",
      "source": [
        "from dirty_cat.datasets._fetching import fetch_midwest_survey\n",
        "from sklearn.model_selection import train_test_split\n",
        "from cu_cat import GapEncoder as cuGapEncoder, TableVectorizer as cuTable\n",
        "from dirty_cat import GapEncoder as dGapEncoder, TableVectorizer as dTable\n",
        "from numpy.testing import assert_array_equal"
      ],
      "metadata": {
        "id": "I9yf26TmukWP"
      },
      "id": "I9yf26TmukWP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = fetch_midwest_survey()\n",
        "X_train, X_test = train_test_split(\n",
        "    dataset.X[[\"What_would_you_call_the_part_of_the_country_you_live_in_now\"]],\n",
        "    random_state=0,\n",
        ")\n",
        "encA = cuGapEncoder(n_components=2, random_state=2)\n",
        "encA.fit_transform(X_train)\n",
        "topics1 = encA.get_feature_names_out()\n",
        "\n",
        "encB = dGapEncoder(n_components=2, random_state=2)\n",
        "encB.fit_transform(X_train)\n",
        "topics2 = encB.get_feature_names_out()\n",
        "\n",
        "assert len(topics1) == len(topics2)\n"
      ],
      "metadata": {
        "id": "fTadx20nu3-5"
      },
      "id": "fTadx20nu3-5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cc_table_vec = cuTable()\n",
        "aa = cc_table_vec.fit_transform((dataset.X))\n",
        "C_out = cc_table_vec.transformers_\n",
        "print(C_out[2]) # print high_card_cat\n",
        "d_table_vec = dTable()\n",
        "aa = d_table_vec.fit_transform((dataset.X))\n",
        "D_out = d_table_vec.transformers_\n",
        "print(D_out[1]) # print high_card_cat"
      ],
      "metadata": {
        "id": "R9xZat1ux8fZ"
      },
      "id": "R9xZat1ux8fZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datasets Explored in the notebook:\n",
        "\n",
        "\\begin{array}{ccc}\n",
        "data&rows&columns&data\\ description\\\\\n",
        "REDDIT&100&6&text-rich\\\\\n",
        "CTU-13&10k&16&IP-address, datetime, numeric, short\\ text\\ labels\\\\\n",
        "redteam&20k&14&messy\\ string, text, other\\\\\n",
        "ask HN&3000&14&title, text, datetime,numerics\\\\\n",
        "20newsgroups&11k&1&paragraphs\\\\\n",
        "winlogs&5M&21&windows\\ log\\ data: sparse,incomplete, hectic\\\\\n",
        "\\end{array}"
      ],
      "metadata": {
        "id": "GbPNTpp81OWt"
      },
      "id": "GbPNTpp81OWt"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ndf_reddit\n",
        "\n",
        "100 rows of `title` and `document` text-rich columns"
      ],
      "metadata": {
        "id": "mtNkphkwkz8Q"
      },
      "id": "mtNkphkwkz8Q"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import graphistry\n",
        "from graphistry.features import topic_model\n",
        "\n",
        "ndf_reddit = pd.read_csv('https://raw.githubusercontent.com/graphistry/pygraphistry/master/graphistry/tests/data/reddit.csv')#'pygraphistry/graphistry/tests/data/reddit.csv')\n",
        "print(ndf_reddit.shape)\n",
        "ndf_reddit.head(5)"
      ],
      "metadata": {
        "id": "waNZVIfhk_Uy"
      },
      "id": "waNZVIfhk_Uy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = graphistry.nodes(ndf_reddit)\n",
        "print(g._nodes.shape, g._edges.shape)\n",
        "g._nodes.head(5)"
      ],
      "metadata": {
        "id": "_TowpvE-lAqU"
      },
      "id": "_TowpvE-lAqU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## run featurize via CPU and GPU and compare speeds, with both results being UMAP-ed on GPU\n",
        "pr = cProfile.Profile()\n",
        "pr.enable()\n",
        "g = graphistry.nodes(ndf_reddit)\n",
        "start0 = time.time()\n",
        "g0a = g.umap(**topic_model,engine='cuml',memoize=False,feature_engine='dirty_cat',cardinality_threshold=10,cardinality_threshold_target=10)\n",
        "end0 = time.time()\n",
        "pr.disable()\n",
        "with open('reddit_dirty_',n_samples,'.txt', 'w') as stream:\n",
        "    stats = Stats(pr,stream=stream)\n",
        "    stats.sort_stats('tottime').print_stats(20)\n",
        "\n",
        "g = graphistry.nodes(cudf.from_pandas(ndf_reddit))\n",
        "pr = cProfile.Profile()\n",
        "pr.enable()\n",
        "start1 = time.time()\n",
        "g0b = g.umap(**topic_model,engine='cuml',memoize=False,feature_engine='cu_cat',cardinality_threshold=10,cardinality_threshold_target=10)\n",
        "end1 = time.time()\n",
        "pr.disable()\n",
        "with open('reddit_cucat_',n_samples,'.txt', 'w') as stream:\n",
        "    stats = Stats(pr,stream=stream)\n",
        "    stats.sort_stats('tottime').print_stats(20)\n",
        "\n",
        "del g, ndf_reddit\n",
        "T0 = end0-start0\n",
        "T1 = end1-start1\n",
        "print('\\nn_samples of reddit data:',n_samples,'\\nCPU dirty_cat runtime:',np.round(T0,4),'\\nGPU cu_cat runtime:',np.round(T1,4),'\\nspeedup:', np.round(T0/T1,4),\n"
      ],
      "metadata": {
        "id": "iVy9rXqakyyL"
      },
      "id": "iVy9rXqakyyL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g0a.plot()"
      ],
      "metadata": {
        "id": "WThRWuIBky47"
      },
      "id": "WThRWuIBky47",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g0b.plot()"
      ],
      "metadata": {
        "id": "4zH-XF8Dky_g"
      },
      "id": "4zH-XF8Dky_g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CTU-13 malware dataset\n",
        "roughly 10k rows of IP-address, date-time, numeric and short text labels"
      ],
      "metadata": {
        "id": "Dpwh-il2G3_j"
      },
      "id": "Dpwh-il2G3_j"
    },
    {
      "cell_type": "code",
      "source": [
        "edf = pd.read_csv('https://gist.githubusercontent.com/silkspace/33bde3e69ae24fee1298a66d1e00b467/raw/dc66bd6f1687270be7098f94b3929d6a055b4438/malware_bots.csv', index_col=0)\n",
        "T = edf.Label.apply(lambda x: True if 'Botnet' in x else False)\n",
        "bot = edf[T]\n",
        "nbot = edf[~T]\n",
        "print(f'Botnet abundance: {100*len(bot)/len(edf):0.2f}%')# so botnet traffic makes up a tiny fraction of total\n",
        "\n",
        "# let's balance the dataset in a 10-1 ratio, for speed and demonstrative purposes\n",
        "negs = nbot.sample(10*len(bot))\n",
        "edf = pd.concat([bot, negs])  # top part of arrays are bot traffic, then all non-bot traffic\n",
        "edf = edf.drop_duplicates()\n",
        "\n",
        "# some useful indicators for later that predict Botnet as Bool and Int\n",
        "Y = edf.Label.apply(lambda x: 1 if 'Botnet' in x else 0)  # np.array(T)\n",
        "\n",
        "# Later we will use and exploit any meaning shared between the labels in a latent distribution\n",
        "\n",
        "# add it to the dataframe\n",
        "edf['bot'] = Y\n",
        "\n",
        "# name some columns for edges and features\n",
        "src = 'SrcAddr'\n",
        "dst = 'DstAddr'\n",
        "good_cols_with_edges = ['Dur', 'Proto', 'Sport',\n",
        "       'Dport', 'State', 'TotPkts', 'TotBytes', 'SrcBytes', src, dst]\n",
        "\n",
        "good_cols_without_edges = ['Dur', 'Proto', 'Sport',\n",
        "       'Dport', 'State', 'TotPkts', 'TotBytes', 'SrcBytes']\n",
        "\n",
        "## some encoding parameters\n",
        "n_topics = 20\n",
        "n_topics_target = 7"
      ],
      "metadata": {
        "id": "-xjql3ywG8DM"
      },
      "id": "-xjql3ywG8DM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(edf.shape())\n",
        "edf.head(5)"
      ],
      "metadata": {
        "id": "mo6Ssnkjm7zt"
      },
      "id": "mo6Ssnkjm7zt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = graphistry.edges(edf, src, dst).materialize_nodes()\n",
        "print(g._nodes.shape, g._edges.shape)\n",
        "g._nodes.head(5)"
      ],
      "metadata": {
        "id": "rt3SnsTcm77L"
      },
      "id": "rt3SnsTcm77L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## run featurize via CPU and GPU and compare speeds, with both results being UMAP-ed on GPU\n",
        "pr = cProfile.Profile()\n",
        "pr.enable()\n",
        "g = graphistry.edges(edf, src, dst)\n",
        "# g = graphistry.nodes(edf[['SrcAddr','DstAddr']])\n",
        "start0 = time.time()\n",
        "g1a = g.umap(kind='edges',\n",
        "            X=good_cols_with_edges,\n",
        "            y = ['bot'],\n",
        "            use_scaler='quantile',\n",
        "            use_scaler_target=None,\n",
        "            cardinality_threshold=20,\n",
        "            cardinality_threshold_target=2,\n",
        "            n_topics=n_topics,\n",
        "            feature_engine='dirty_cat',\n",
        "            engine='cuml',\n",
        "            memoize=False,\n",
        "            n_topics_target=n_topics_target,\n",
        "            n_bins=n_topics_target,\n",
        "            metric='euclidean',\n",
        "            n_neighbors=12)\n",
        "end0 = time.time()\n",
        "pr.disable()\n",
        "with open('ctu13_dirty_',n_samples,'.txt', 'w') as stream:\n",
        "    stats = Stats(pr,stream=stream)\n",
        "    stats.sort_stats('tottime').print_stats(20)\n",
        "\n",
        "g = graphistry.edges(cudf.from_pandas(edf), src, dst)\n",
        "# g = graphistry.nodes(edf[['SrcAddr','DstAddr']])\n",
        "pr = cProfile.Profile()\n",
        "pr.enable()\n",
        "start1 = time.time()\n",
        "g1a = g.umap(kind='edges',\n",
        "            X=good_cols_with_edges,\n",
        "            y = ['bot'],\n",
        "            use_scaler='quantile',\n",
        "            use_scaler_target=None,\n",
        "            cardinality_threshold=20,\n",
        "            cardinality_threshold_target=2,\n",
        "            n_topics=n_topics,\n",
        "            feature_engine='cu_cat',\n",
        "            engine='cuml',\n",
        "            memoize=False,\n",
        "            n_topics_target=n_topics_target,\n",
        "            n_bins=n_topics_target,\n",
        "            metric='euclidean',\n",
        "            n_neighbors=12)\n",
        "end1 = time.time()\n",
        "pr.disable()\n",
        "with open('ctu13_cucat_',n_samples,'.txt', 'w') as stream:\n",
        "    stats = Stats(pr,stream=stream)\n",
        "    stats.sort_stats('tottime').print_stats(20)\n",
        "\n",
        "del g, edf\n",
        "T0 = end0-start0\n",
        "T1 = end1-start1\n",
        "print('\\nn_samples of CTU data:',n_samples,'\\nCPU dirty_cat runtime:',np.round(T0,4),'\\nGPU cu_cat runtime:',np.round(T1,4),'\\nspeedup:', np.round(T0/T1,4),\n"
      ],
      "metadata": {
        "id": "Ds6kkw7Sm6zg"
      },
      "id": "Ds6kkw7Sm6zg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g1a.plot()"
      ],
      "metadata": {
        "id": "t6BdEPMTnkep"
      },
      "id": "t6BdEPMTnkep",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g1b.plot()"
      ],
      "metadata": {
        "id": "T9VTluBynknA"
      },
      "id": "T9VTluBynknA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9fa2d4e-53e8-4eb5-bdbf-c5c1908159ad"
      },
      "source": [
        "## redteam\n",
        "\n",
        "around 20k rows of messy string, text and other columns needing parsing"
      ],
      "id": "b9fa2d4e-53e8-4eb5-bdbf-c5c1908159ad"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fe52faa-c35c-492e-98c1-7cfc46888a5f"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('https://gist.githubusercontent.com/silkspace/c7b50d0c03dc59f63c48d68d696958ff/raw/31d918267f86f8252d42d2e9597ba6fc03fcdac2/redteam_50k.csv', index_col=0)\n",
        "red_team = pd.read_csv('https://gist.githubusercontent.com/silkspace/5cf5a94b9ac4b4ffe38904f20d93edb1/raw/888dabd86f88ea747cf9ff5f6c44725e21536465/redteam_labels.csv', index_col=0)\n",
        "df['feats'] = df.src_computer + ' ' + df.dst_computer + ' ' + df.auth_type + ' ' + df.logontype\n",
        "df['feats2'] = df.src_computer + ' ' + df.dst_computer\n",
        "ndf = df.drop_duplicates(subset=['feats'])\n",
        "tdf = pd.concat([red_team.reset_index(), ndf.reset_index()])\n",
        "tdf['node'] = range(len(tdf))"
      ],
      "id": "3fe52faa-c35c-492e-98c1-7cfc46888a5f"
    },
    {
      "cell_type": "code",
      "source": [
        "tdf.head(5)"
      ],
      "metadata": {
        "id": "9jplhXKapKaF"
      },
      "id": "9jplhXKapKaF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = graphistry.nodes((tdf), 'node')\n",
        "print(g._nodes.shape, g._edges.shape)\n",
        "g._nodes.head(5)"
      ],
      "metadata": {
        "id": "srar5cW8pKhc"
      },
      "id": "srar5cW8pKhc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## run featurize via CPU and GPU and compare speeds, with both results being UMAP-ed on GPU\n",
        "for n_samples in [5000,10000,15000]:\n",
        "    tdfA=tdf.sample(n_samples,replace=False)\n",
        "    pr = cProfile.Profile()\n",
        "    pr.enable()\n",
        "    g = graphistry.nodes((tdfA), 'node')\n",
        "    start0 = time.time()\n",
        "    g2a = g.umap(X=['feats'],\n",
        "                min_words=1000000, # force high so that we don't use Sentence Transformers\n",
        "                cardinality_threshold=4, # set low so we force topic model\n",
        "                n_topics=32, # number of topics\n",
        "                use_scaler=None,\n",
        "                feature_engine='dirty_cat',\n",
        "                memoize=False,\n",
        "                engine='cuml',\n",
        "                use_scaler_target=None\n",
        "            )\n",
        "    end0 = time.time()\n",
        "    pr.disable()\n",
        "    with open('ctu13_dirty_',n_samples,'.txt', 'w') as stream:\n",
        "        stats = Stats(pr,stream=stream)\n",
        "        stats.sort_stats('tottime').print_stats(20)\n",
        "\n",
        "    g = graphistry.nodes(cudf.from_pandas(tdfA), 'node')\n",
        "    pr = cProfile.Profile()\n",
        "    pr.enable()\n",
        "    start1 = time.time()\n",
        "    g2a = g.umap(X=['feats'],\n",
        "                min_words=1000000, # force high so that we don't use Sentence Transformers\n",
        "                cardinality_threshold=4, # set low so we force topic model\n",
        "                n_topics=32, # number of topics\n",
        "                use_scaler=None,\n",
        "                feature_engine='cu_cat',\n",
        "                memoize=False,\n",
        "                engine='cuml',\n",
        "                use_scaler_target=None\n",
        "            )\n",
        "    end0 = time.time()\n",
        "    pr.disable()\n",
        "    with open('ctu13_cucat_',n_samples,'.txt', 'w') as stream:\n",
        "        stats = Stats(pr,stream=stream)\n",
        "        stats.sort_stats('tottime').print_stats(20)\n",
        "\n",
        "    del g, tdfA\n",
        "    T0 = end0-start0\n",
        "    T1 = end1-start1\n",
        "    print('\\nn_samples of redteam data:',n_samples,'\\nCPU dirty_cat runtime:',np.round(T0,4),'\\nGPU cu_cat runtime:',np.round(T1,4),'\\nspeedup:', np.round(T0/T1,4),\n"
      ],
      "metadata": {
        "id": "9z-ab6Jknpfx"
      },
      "id": "9z-ab6Jknpfx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g2a.plot()"
      ],
      "metadata": {
        "id": "OSDMeFLgpyNr"
      },
      "id": "OSDMeFLgpyNr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g2b.plot()"
      ],
      "metadata": {
        "id": "1Po6Z192pyXA"
      },
      "id": "1Po6Z192pyXA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1f6bcea-42c9-4f00-baf1-86e4c4349434"
      },
      "source": [
        "## ask HN\n",
        "3000 rows of `title` and `text` columns similar to ndf_reddit dataframe, plus several disparate `time-stamp` columns and various numerics"
      ],
      "id": "a1f6bcea-42c9-4f00-baf1-86e4c4349434"
    },
    {
      "cell_type": "code",
      "source": [
        "# # get the data top 3000 posts on Hacker News\n",
        "askHNA = pd.read_csv('https://storage.googleapis.com/cohere-assets/blog/text-clustering/data/askhn3k_df.csv', index_col=0)\n",
        "print(askHNA.shape)\n",
        "askHNA.head(5)"
      ],
      "metadata": {
        "id": "HaAs1cAWjSAc"
      },
      "id": "HaAs1cAWjSAc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = graphistry.nodes(askHNA)\n",
        "print(g._nodes.shape, g._edges.shape)\n",
        "g._nodes.head(5)"
      ],
      "metadata": {
        "id": "3M64HmTljaI5"
      },
      "id": "3M64HmTljaI5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## run featurize via CPU and GPU and compare speeds, with both results being UMAP-ed on GPU\n",
        "for n_samples in [500,1000,2000]:\n",
        "    askHN = askHNA.sample(n_samples,replace=False)\n",
        "    pr = cProfile.Profile()\n",
        "    pr.enable()\n",
        "    g = graphistry.nodes(askHN)\n",
        "    start0 = time.time()\n",
        "    g5a = g.umap(engine='cuml',memoize=False,feature_engine='dirty_cat',cardinality_threshold=10,cardinality_threshold_target=10)\n",
        "    end0 = time.time()\n",
        "    pr.disable()\n",
        "    with open('hn_dirty_',n_samples,'.txt', 'w') as stream:\n",
        "        stats = Stats(pr,stream=stream)\n",
        "        stats.sort_stats('tottime').print_stats(20)\n",
        "\n",
        "    g = graphistry.nodes(cudf.from_pandas(askHN))\n",
        "    pr = cProfile.Profile()\n",
        "    pr.enable()\n",
        "    start1 = time.time()\n",
        "    g5b = g.umap(engine='cuml',memoize=False,feature_engine='cu_cat',cardinality_threshold=10,cardinality_threshold_target=10)\n",
        "    end0 = time.time()\n",
        "    pr.disable()\n",
        "    with open('hn_cucat_',n_samples,'.txt', 'w') as stream:\n",
        "        stats = Stats(pr,stream=stream)\n",
        "        stats.sort_stats('tottime').print_stats(20)\n",
        "\n",
        "    del g, askHN\n",
        "    T0 = end0-start0\n",
        "    T1 = end1-start0\n",
        "    print('\\nn_samples of HN data:',n_samples,'\\nCPU dirty_cat runtime:',np.round(T0,4),'\\nGPU cu_cat runtime:',np.round(T1,4),'\\nspeedup:', np.round(T0/T1,4),\n"
      ],
      "metadata": {
        "id": "NVbDfOBidU_X"
      },
      "id": "NVbDfOBidU_X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g3a.plot()"
      ],
      "metadata": {
        "id": "cLpC3O6hfmxr"
      },
      "id": "cLpC3O6hfmxr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g3b.plot()"
      ],
      "metadata": {
        "id": "qHSWAp6afpvY"
      },
      "id": "qHSWAp6afpvY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6657b008-5094-42fd-96a8-177edf7e5ebd"
      },
      "source": [
        "## 20newsgroups\n",
        "11k massive, single column containing multi-sentences to multi-paragraphs"
      ],
      "id": "6657b008-5094-42fd-96a8-177edf7e5ebd"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "news, _ = fetch_20newsgroups(\n",
        "    shuffle=True,\n",
        "    random_state=1,\n",
        "    remove=(\"headers\", \"footers\", \"quotes\"),\n",
        "    return_X_y=True,\n",
        ")\n",
        "print(news.shape)\n",
        "news.head(5)"
      ],
      "metadata": {
        "id": "f41HXB6PjtSc"
      },
      "id": "f41HXB6PjtSc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = graphistry.nodes(news)\n",
        "print(g._nodes.shape, g._edges.shape)\n",
        "g._nodes.head(5)"
      ],
      "metadata": {
        "id": "fQRoSHHWjx_6"
      },
      "id": "fQRoSHHWjx_6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## run featurize via CPU and GPU and compare speeds, with both results being UMAP-ed on GPU\n",
        "for n_samples in [500,1000,2000]:\n",
        "    newsA = news[:n_samples]\n",
        "    newsA=pd.DataFrame(newsA)\n",
        "    pr = cProfile.Profile()\n",
        "    pr.enable()\n",
        "    g = graphistry.nodes(newsA)\n",
        "    start0 = time.time()\n",
        "    g5a = g.umap(engine='cuml',memoize=False,feature_engine='dirty_cat',cardinality_threshold=10,cardinality_threshold_target=10)\n",
        "    end0 = time.time()\n",
        "    pr.disable()\n",
        "    with open('news_dirty_',n_samples,'.txt', 'w') as stream:\n",
        "        stats = Stats(pr,stream=stream)\n",
        "        stats.sort_stats('tottime').print_stats(20)\n",
        "\n",
        "    g = graphistry.nodes(cudf.from_pandas(newsA))\n",
        "    pr = cProfile.Profile()\n",
        "    pr.enable()\n",
        "    start1 = time.time()\n",
        "    g5b = g.umap(engine='cuml',memoize=False,feature_engine='cu_cat',cardinality_threshold=10,cardinality_threshold_target=10)\n",
        "    end0 = time.time()\n",
        "    pr.disable()\n",
        "    with open('news_cucat_',n_samples,'.txt', 'w') as stream:\n",
        "        stats = Stats(pr,stream=stream)\n",
        "        stats.sort_stats('tottime').print_stats(20)\n",
        "\n",
        "    del g, newsA\n",
        "    T0 = end0-start0\n",
        "    T1 = end1-start0\n",
        "    print('\\nn_samples of news data:',n_samples,'\\nCPU dirty_cat runtime:',np.round(T0,4),'\\nGPU cu_cat runtime:',np.round(T1,4),'\\nspeedup:', np.round(T0/T1,4),\n"
      ],
      "metadata": {
        "id": "fbBUOiHqfINX"
      },
      "id": "fbBUOiHqfINX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g4a.plot()"
      ],
      "metadata": {
        "id": "loBxOzEVf4fS"
      },
      "id": "loBxOzEVf4fS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g4b.plot()"
      ],
      "metadata": {
        "id": "6u86LKZvf4yK"
      },
      "id": "6u86LKZvf4yK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2eafa7a-9b51-492a-ab0e-ed7ec89a2a6f"
      },
      "source": [
        "## winlogs\n",
        "5M rows of windows log data, including 21 columns of sparse, incomplete and generally hecticly \"structured\" data. `cu-cat` shines as you scale rows up!"
      ],
      "id": "f2eafa7a-9b51-492a-ab0e-ed7ec89a2a6f"
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://www.dropbox.com/s/31dx1g6g59exoc3/part.88.parquet\n",
        "winlogs=pd.read_parquet('part.88.parquet')\n",
        "print(winlogs.shape)\n",
        "winlogs.head(5)"
      ],
      "metadata": {
        "id": "er9uLtYVj3Yp"
      },
      "id": "er9uLtYVj3Yp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = graphistry.nodes(winlogsA)\n",
        "print(g._nodes.shape, g._edges.shape)\n",
        "g._nodes.head(5)"
      ],
      "metadata": {
        "id": "viqiuT_Aj54I"
      },
      "id": "viqiuT_Aj54I",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for n_samples in [5000,10000,20000]:\n",
        "    winlogsA=winlogs.sample(n_samples,replace=False)\n",
        "    pr = cProfile.Profile()\n",
        "    pr.enable()\n",
        "    g = graphistry.nodes(winlogsA)\n",
        "    start0 = time.time()\n",
        "    g5a = g.umap(engine='cuml',memoize=False,feature_engine='dirty_cat',cardinality_threshold=10,cardinality_threshold_target=10)\n",
        "    end0 = time.time()\n",
        "    pr.disable()\n",
        "    with open('winlogs_dirty_',n_samples,'.txt', 'w') as stream:\n",
        "        stats = Stats(pr,stream=stream)\n",
        "        stats.sort_stats('tottime').print_stats(20)\n",
        "\n",
        "    g = graphistry.nodes(cudf.from_pandas(winlogs))\n",
        "    pr = cProfile.Profile()\n",
        "    pr.enable()\n",
        "    start1 = time.time()\n",
        "    g5b = g.umap(engine='cuml',memoize=False,feature_engine='cu_cat',cardinality_threshold=10,cardinality_threshold_target=10)\n",
        "    end0 = time.time()\n",
        "    pr.disable()\n",
        "    with open('winlogs_cucat_',n_samples,'.txt', 'w') as stream:\n",
        "        stats = Stats(pr,stream=stream)\n",
        "        stats.sort_stats('tottime').print_stats(20)\n",
        "\n",
        "    del g, winlogsA\n",
        "    T0 = end0-start0\n",
        "    T1 = end1-start0\n",
        "    print('\\nn_samples of winlogs data:',n_samples,'\\nCPU dirty_cat runtime:',np.round(T0,4),'\\nGPU cu_cat runtime:',np.round(T1,4),'\\nspeedup:', np.round(T0/T1,4),\n"
      ],
      "metadata": {
        "id": "kcy-PndCf-kX"
      },
      "id": "kcy-PndCf-kX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g5a.plot()"
      ],
      "metadata": {
        "id": "GxGqXMHJhjBr"
      },
      "id": "GxGqXMHJhjBr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g5b.plot()"
      ],
      "metadata": {
        "id": "9aDhFpnjhlYQ"
      },
      "id": "9aDhFpnjhlYQ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}