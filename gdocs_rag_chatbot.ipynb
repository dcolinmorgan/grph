{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dcolinmorgan/grph/blob/main/gdocs_rag_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJO2rllsnFNB"
      },
      "source": [
        "# Building RAG Chatbot with LangChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vyYa6MtBnFNB"
      },
      "outputs": [],
      "source": [
        "# !pip install -qU \\\n",
        "#     langchain \\\n",
        "#     openai \\\n",
        "#     datasets \\\n",
        "#     tiktoken \\\n",
        "#     opensearch-py \\\n",
        "#     langchain_community \\\n",
        "#     langchain_text_splitters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6g6gIO8GnFNC"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# from langchain.chat_models import ChatOpenAI\n",
        "# from google.colab import userdata\n",
        "\n",
        "# OS_TOKEN = userdata.get('OS_TOKEN')\n",
        "# os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "# os.environ[\"OS_TOKEN\"] = userdata.get('OS_TOKEN')\n",
        "# chat = ChatOpenAI(\n",
        "#     openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
        "#     model='gpt-3.5-turbo'\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## setup generic OS gpy.docs index"
      ],
      "metadata": {
        "id": "hNp3CS6D0UgO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ke3NTBWJnFNI"
      },
      "outputs": [],
      "source": [
        "# from langchain_community.document_loaders import TextLoader\n",
        "# from langchain_community.vectorstores import OpenSearchVectorSearch\n",
        "from langchain_community.embeddings import OpenAIEmbeddings\n",
        "# from langchain_text_splitters import CharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain sentence-transformers opensearch-py"
      ],
      "metadata": {
        "id": "Wx9xVaAF2OFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# from langchain.chat_models import ChatOpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "OS_TOKEN = userdata.get('OS_TOKEN')\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ[\"OS_TOKEN\"] = userdata.get('OS_TOKEN')\n",
        "os.environ[\"HF_TOKEN\"] = userdata.get('HF_TOKEN')\n",
        "# chat = ChatOpenAI(\n",
        "#     openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
        "#     model='gpt-3.5-turbo'\n",
        "# )"
      ],
      "metadata": {
        "id": "74sM_ZQT4Rtx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "# init open-source embedding model (downloaded from hugging-face hub)\n",
        "# embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
        "embeddings = OpenAIEmbeddings()\n",
        "embed_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
      ],
      "metadata": {
        "id": "OxfWcXg72Rmd",
        "outputId": "2df3af0b-97e5-438f-8df2-f67f2399b1df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# embeddings"
      ],
      "metadata": {
        "id": "kadmxrTx9wLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RWt-T7CTnFNI"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import OpenSearchVectorSearch\n",
        "\n",
        "# Init OpenSearch client connection\n",
        "docsearch = OpenSearchVectorSearch(\n",
        "     index_name=\"pygraphistry-docs\",  # TODO: use the same index-name used in the ingestion script\n",
        "     embedding_function=embeddings,\n",
        "     opensearch_url=OS_TOKEN,  # TODO: e.g. use the AWS OpenSearch domain instantiated previously\n",
        "#     http_auth=(\"<<insert_user_name>>\", \"<<insert_password>>\"),\n",
        "#     use_ssl = False,\n",
        "#     verify_certs = False,\n",
        "#     ssl_assert_hostname = False,\n",
        "#     ssl_show_warn = False,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docsearch.engine"
      ],
      "metadata": {
        "id": "AkainX7m7Iwn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How can i use gfql chain?\"\n",
        "docs = docsearch.similarity_search(query, k=10)"
      ],
      "metadata": {
        "id": "zCxkqKi25wDv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "DpLZrzZMnFNJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d07e44b7-6f87-4561-a2b3-7d029bb6a2f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "See help(g.dbscan) or help(g.transform_dbscan) for options\n",
            "Quickly configurable\n",
            "Set visual attributes through quick data bindings and set all sorts of URL options. Check out the tutorials on colors, sizes, icons, badges, weighted clustering and sharing controls:\n",
            "  g\n",
            "    .privacy(mode='private', invited_users=[{'email': 'friend1@site.ngo', 'action': '10'}], notify=False)\n",
            "    .edges(df, 'col_a', 'col_b')\n",
            "    .edges(my_transform1(g._edges))\n",
            "    .nodes(df, 'col_c')\n",
            "    .nodes(my_transform2(g._nodes))\n",
            "    .bind(source='col_a', destination='col_b', node='col_c')\n",
            "    .bind(\n",
            "      point_color='col_a',\n",
            "      point_size='col_b',\n",
            "      point_title='col_c',\n",
            "      point_x='col_d',\n",
            "      point_y='col_e')\n",
            "    .bind(\n",
            "      edge_color='col_m',\n",
            "      edge_weight='col_n',\n",
            "      edge_title='col_o')\n",
            "    .encode_edge_color('timestamp', [\"blue\", \"yellow\", \"red\"], as_continuous=True)\n",
            "    .encode_point_icon('device_type', categorical_mapping={'macbook': 'laptop', ...})\n"
          ]
        }
      ],
      "source": [
        "print(docs[0].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docsearch = OpenSearchVectorSearch.from_documents(\n",
        "    docs,\n",
        "    embeddings,\n",
        "    index_name=\"pygraphistry-docs\",  # TODO: use the same index-name used in the ingestion script\n",
        "    # embedding_function=embeddings,\n",
        "    opensearch_url=OS_TOKEN,\n",
        "    engine=\"faiss\",\n",
        "    space_type=\"innerproduct\",\n",
        "    ef_construction=256,\n",
        "    m=48,\n",
        ")\n",
        "\n",
        "# query = \"how\"\n",
        "docs = docsearch.similarity_search(query)"
      ],
      "metadata": {
        "id": "8yqv12y26M_A"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs[0].page_content)"
      ],
      "metadata": {
        "id": "smM91v9D6bHg",
        "outputId": "8085669d-77fd-4fd5-e6b6-f68048898480",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "See help(g.dbscan) or help(g.transform_dbscan) for options\n",
            "Quickly configurable\n",
            "Set visual attributes through quick data bindings and set all sorts of URL options. Check out the tutorials on colors, sizes, icons, badges, weighted clustering and sharing controls:\n",
            "  g\n",
            "    .privacy(mode='private', invited_users=[{'email': 'friend1@site.ngo', 'action': '10'}], notify=False)\n",
            "    .edges(df, 'col_a', 'col_b')\n",
            "    .edges(my_transform1(g._edges))\n",
            "    .nodes(df, 'col_c')\n",
            "    .nodes(my_transform2(g._nodes))\n",
            "    .bind(source='col_a', destination='col_b', node='col_c')\n",
            "    .bind(\n",
            "      point_color='col_a',\n",
            "      point_size='col_b',\n",
            "      point_title='col_c',\n",
            "      point_x='col_d',\n",
            "      point_y='col_e')\n",
            "    .bind(\n",
            "      edge_color='col_m',\n",
            "      edge_weight='col_n',\n",
            "      edge_title='col_o')\n",
            "    .encode_edge_color('timestamp', [\"blue\", \"yellow\", \"red\"], as_continuous=True)\n",
            "    .encode_point_icon('device_type', categorical_mapping={'macbook': 'laptop', ...})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# sprinkle in OpenAI magic"
      ],
      "metadata": {
        "id": "90tBsp_dAHh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import (\n",
        "    SystemMessage,\n",
        "    HumanMessage,\n",
        "    AIMessage\n",
        ")\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
        "    HumanMessage(content=\"Hi AI, how are you today?\"),\n",
        "    AIMessage(content=\"I'm great thank you. How can I help you?\"),\n",
        "    HumanMessage(content=\"I'd like to understand string theory.\")\n",
        "]"
      ],
      "metadata": {
        "id": "wwQR_T68-VI3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n"
      ],
      "metadata": {
        "id": "aVgAeahN-fGp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI(\n",
        "    openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
        "    model='gpt-3.5-turbo'\n",
        ")"
      ],
      "metadata": {
        "id": "_gb9Jtwr-ayl",
        "outputId": "66f2d1a7-2982-40e1-eb9c-821278e78774",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_prompt(query: str):\n",
        "    # get top 3 results from knowledge base\n",
        "    results = docsearch.similarity_search(query, k=3)\n",
        "    # get the text from the results\n",
        "    source_knowledge = \"\\n\".join([x.page_content for x in results])\n",
        "    # feed into an augmented prompt\n",
        "    augmented_prompt = f\"\"\"Using the contexts below, answer the query.\n",
        "\n",
        "    Contexts:\n",
        "    {source_knowledge}\n",
        "\n",
        "    Query: {query}\"\"\"\n",
        "    return augmented_prompt"
      ],
      "metadata": {
        "id": "qCTjpBmY-qtF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = HumanMessage(\n",
        "    content=augment_prompt(\n",
        "        \"how can i use UMAP in pygraphistry?\"\n",
        "    )\n",
        ")\n",
        "\n",
        "res = chat(messages + [prompt])\n",
        "print(res.content)"
      ],
      "metadata": {
        "id": "aMUZyBQp6fLV",
        "outputId": "fa42d0ef-5e2c-4d6a-9cc9-ca9734a37e65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To use UMAP in PyGraphistry, you can install PyGraphistry with the optional `graphistry[ai]` dependencies. This will add support for UMAP along with other features like automatic feature engineering and graph neural net support. Once you have PyGraphistry installed with the necessary dependencies, you can then use the UMAP functionality in your Python code to analyze and visualize big graphs efficiently.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = HumanMessage(\n",
        "    content=augment_prompt(\n",
        "        \"how can i run gfql in pygraphistry?\"\n",
        "    )\n",
        ")\n",
        "\n",
        "res = chat(messages + [prompt])\n",
        "print(res.content)"
      ],
      "metadata": {
        "id": "jFyRb3uH-zdJ",
        "outputId": "534cbf53-4a50-4d33-830e-98387e4989c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To run GFQL (Graphistry Filter Query Language) in PyGraphistry, you can use the `gfql` parameter in the `PyGraphistry.bind()` function. This allows you to filter your data directly in your PyGraphistry visualizations. Here's a simple example:\n",
            "\n",
            "```python\n",
            "import graphistry\n",
            "\n",
            "# Insert your GFQL query here\n",
            "my_gfql_query = \"node.name == 'Alice'\"\n",
            "\n",
            "# Bind your data to PyGraphistry and apply the GFQL query\n",
            "g = graphistry.bind()  \n",
            "g = g.gfql(my_gfql_query)\n",
            "\n",
            "# Visualize your data\n",
            "g.plot()\n",
            "```\n",
            "\n",
            "This code snippet shows how you can use the `gfql()` method to apply your GFQL query to filter your data before visualizing it using PyGraphistry.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y8pWFUH9-f30"
      },
      "execution_count": 19,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "redacre",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}